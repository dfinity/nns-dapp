# Verify that the aggregator gets the required data
name: Aggregator aggregates
on:
  push:
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
defaults:
  run:
    shell: bash -euxlo pipefail {0}
jobs:
  curl_test:
    runs-on: ubuntu-20.04
    timeout-minutes: 60
    steps:
      - name: Checkout nns-dapp
        uses: actions/checkout@v3
      - name: Set up docker buildx
        uses: docker/setup-buildx-action@v2
      - name: Build sns-aggregator image
        uses: docker/build-push-action@v3
        with:
          context: .
          file: Dockerfile
          build-args: |
            DFX_NETWORK=local
          cache-from: type=gha,scope=cached-stage
          # Exports the artefacts from the final stage
          outputs: ./out
      - name: Get SNS scripts
        uses: actions/checkout@v3
        with:
          repository: 'dfinity/snsdemo'
          path: 'snsdemo'
          # Version from Apr 4 2023 with xz compressed state
          ref: '8160f742e10fbd1ac89549a5880ae047ff8f290d'
      - name: Add SNS scripts to the path
        run: |
          echo "$PWD/snsdemo/bin" >> $GITHUB_PATH
      - name: Install tools
        run: |
          dfx-software-dfx-install --version "$(jq -r .dfx dfx.json)"
          dfx-software-idl2json-install --version "v$(jq -r .defaults.build.config.IDL2JSON_VERSION dfx.json)"
      - name: Get test environment
        run: |
          curl -fL --retry 5 https://github.com/dfinity/snsdemo/releases/download/tip/state.tar.xz > state.tar.xz
          dfx-snapshot-restore --snapshot state.tar.xz --verbose
          dfx identity use snsdemo8
          dfx-sns-demo-healthcheck
      - name: Upgrade to the current aggregator
        run: |
          cp out/sns_aggregator_dev.wasm sns_aggregator.wasm
          # Note: Pretty much any argument values will do; the canister will be reconfigured.
          dfx canister install sns_aggregator --wasm sns_aggregator.wasm --upgrade-unchanged '(opt record { update_interval_ms = 1000; fast_interval_ms = 1_000_000_000; })'
      - name: Make the aggregator collect data quickly
        run: dfx canister call sns_aggregator reconfigure '(opt record { update_interval_ms = 100; fast_interval_ms = 1_000_000_000; })'
      - name: Wait for the aggregator to get data
        run: sleep 120
        # sleep time > 12 SnS & 2 block heights each + a few extra calls.
        # TODO: The aggregator can be installed and populated in the saved state, so this sleep is not needed.
      - name: Get the latest data from the sns aggregator
        run: |
          AGGREGATOR_CANISTER_ID="$(dfx canister id sns_aggregator)"
          curl -Lf "http://${AGGREGATOR_CANISTER_ID}.localhost:8080/v1/sns/list/latest/slow.json" | tee aggregate-1.json
          expect=10
          actual="$(jq length aggregate-1.json)"
          (( expect == actual ))  || {
            echo ERROR: Expected to have $expect SNS in the aggregator but found $actual.
            scripts/sns/aggregator/get_log
          }
      - name: Get the first page of data from the sns aggregator
        run: |
          AGGREGATOR_CANISTER_ID="$(dfx canister id sns_aggregator)"
          curl --retry 5 -Lf "http://${AGGREGATOR_CANISTER_ID}.localhost:8080/v1/sns/list/page/0/slow.json" | tee aggregate-1.json || {
            echo "ERROR: Failed to get data."
            scripts/sns/aggregator/get_log
          }
          expect=10
          actual="$(jq length aggregate-1.json)"
          (( expect == actual ))  || {
            echo ERROR: Expected to have $expect SNS in the aggregator but found $actual.
            scripts/sns/aggregator/get_log
          }
      - name: Get the second page of data from the sns aggregator
        run: |
          AGGREGATOR_CANISTER_ID="$(dfx canister id sns_aggregator)"
          curl -Lf "http://${AGGREGATOR_CANISTER_ID}.localhost:8080/v1/sns/list/page/1/slow.json" | tee aggregate-1.json
          expect=2
          actual="$(jq length aggregate-1.json)"
          (( expect == actual ))  || {
            echo ERROR: Expected to have $expect SNS in the aggregator but found $actual.
          }
      - name: Get logs
        run: |
          scripts/sns/aggregator/get_log > ,logs
          LOG_LINES="$(wc -l <,logs)"
          (( LOG_LINES > 10 )) || {
            echo "ERROR: Expected a non-trivial number of lines to have been logged by now but found only ${LOG_LINES}"
            cat ,logs
            exit 1
          }
      - name: Upgrade the aggregator to self with a slow refresh rate
        run: dfx canister install --mode upgrade --wasm sns_aggregator.wasm --upgrade-unchanged sns_aggregator '(opt record { update_interval_ms = 1_000_000_000; fast_interval_ms = 1_000_000_000; })'
      - name: Expect the first page of data to be retained over the upgrade
        run: |
          AGGREGATOR_CANISTER_ID="$(dfx canister id sns_aggregator)"
          curl -Lf "http://${AGGREGATOR_CANISTER_ID}.localhost:8080/v1/sns/list/page/0/slow.json" | tee aggregate-1.json
          expect=10
          actual="$(jq length aggregate-1.json)"
          (( expect == actual ))  || {
            echo ERROR: Expected to have $expect SNS in the aggregator but found $actual.
          }
      - name: Expect the latest data to be retained over the upgrade
        run: |
          AGGREGATOR_CANISTER_ID="$(dfx canister id sns_aggregator)"
          curl -Lf "http://${AGGREGATOR_CANISTER_ID}.localhost:8080/v1/sns/list/latest/slow.json" | tee aggregate-1.json
          expect=10
          actual="$(jq length aggregate-1.json)"
          (( expect == actual ))  || {
            echo ERROR: Expected to have $expect SNS in the aggregator but found $actual.
          }
      - name: Expect the upstream data to be retained over the upgrade
        run: |
          ./scripts/sns/aggregator/get_stable_data
          expect=12
          actual="$(jq '.sns_cache.upstream_data | length' stable_data.json)"
          (( expect == actual ))  || {
            echo ERROR: Expected to have $expect SNS in the aggregator upstream data but found $actual.
          }
      - name: Downgrade to prod and upgrade back again
        run: |
          set -euxo pipefail
          git fetch --depth 1 origin tag aggregator-prod
          diff="$(git diff tags/aggregator-prod rs/sns_aggregator)"
          if test -n "${diff:-}"
          then ./scripts/sns/aggregator/downgrade-upgrade-test -w sns_aggregator.wasm --verbose
          else echo "Skipping test as there are no relevant code changes"
          fi
      - name: Stop replica
        run: dfx stop
  aggregator-pass:
    needs: ["curl_test"]
    if: ${{ always() }}
    runs-on: ubuntu-20.04
    steps:
      - name: Checks workflow passes
        run: |
          if echo '${{ toJson(needs) }}' | jq 'to_entries[] | select(.value.result != "success")' | grep .
          then echo "You shall not pass:  Some required tests did not succeed"
               exit 1
          else echo "Congratulations, young Frodo."
          fi
